# **DemoGPT**

## Синопcис
Однажды, решив обучить GPT я нашёл достойного размера (около 4 Гб) русский датасет, взял NanoGPT и запустил токенизацию. Ответ убил - вечная токенизация в однопоток и MemoryError из-за загрузки всего датасета в ОЗУ. Стало очевидно, что NanoGPT не подходит для чего то большего чем обучения на микроскопическиъ датасетах. Так и появилась идея этого проекта.

## Описание проекта
Проект задумывается как end-to-end платформа для обучения трансформерных моделей. Если NanoGPT - демонстрационная модель для погружения в архитектуру LLM, допускающая упрощения ради интерпретируемости и не ставящая приоритетом эффективность, то DemoGPT задумывается как No-code инструмент, где любой сможет обучить трансформер, просто отредактировав YAML-конфиг.

Уже сейчас возможно через редактирование dataset_config.yaml управлять загрузкой нужного датасета, его сплита и сабсета. Настраивать параметры очистки данных и нормализации данных. Управлять специальными токенами и тэгами. 

По технической части:
- Создан парсер, с гибкой настройкой.
- Реализован стриминг данных для токенизатора.
- Реализовано распаралеливание токенизации.
- Уже есть возможность обучить трансформер и генерировтаь им текст.

В будущем планируется:
- Реализация концепции "проекта", как сущности, позволяющей хранить структурировано все модели, датасеты и конфиги в рамкой одной логической задачи.
- Добавление возможности дообучения модели, и обучения моделей в несколько этапов(Например первый этап - обучение базовой грамматике языка на общем датасете, второй этап обучение ведения диалога (chat style) на диалоговом датасете).
- Системное улучшение и оптимизация.
- Работа над No-code подходом.


**DemoGPT задумывается,  как готовый инструмент для воплощения идей LLM энтузиастов.**

---

  Проект на очень раннем этапе разработки. Осторожно, в коде содержится навайбкоженый код.
